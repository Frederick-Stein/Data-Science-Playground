{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi2llbYhc5Ts7ksa1UdWVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frederick-Stein/Data-Science-Playground/blob/main/MiniTransfomer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN8Wyz1dKeG8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## mini sentence\n",
        "token_to_id = {\n",
        "    \"what\": 0,\n",
        "    \"is\": 1,\n",
        "    \"the\": 2,\n",
        "    \"weather\": 3,\n",
        "    \"today\": 4,\n",
        "    \"sunny\": 5,\n",
        "    'rainy': 6,\n",
        "    'tomorrow': 7,\n",
        "    \"<EOS>\": 8,\n",
        "    }\n",
        "\n",
        "id_to_token = {v: k for k, v in token_to_id.items()}\n",
        "\n",
        "# input_sentence = \"what is the weather today <EOS> sunny\"\n",
        "# output_sentence = \"is the weather today <EOS> sunny <EOS>\"\n",
        "\n",
        "# input_tokens = input_sentence.split()\n",
        "# output_tokens = output_sentence.split()\n",
        "\n",
        "# input_ids = torch.tensor([token_to_id[token] for token in input_tokens])\n",
        "# output_ids = torch.tensor([token_to_id[token] for token in output_tokens])\n",
        "\n",
        "\n",
        "input_ids = torch.tensor([[token_to_id[\"what\"], token_to_id[\"is\"], token_to_id[\"the\"], token_to_id[\"weather\"], token_to_id[\"today\"], token_to_id[\"<EOS>\"], token_to_id[\"sunny\"]],\n",
        "                       [token_to_id[\"the\"], token_to_id['weather'], token_to_id['tomorrow'], token_to_id['is'], token_to_id['what'], token_to_id['<EOS>'], token_to_id['rainy']]\n",
        "                       ])\n",
        "\n",
        "output_ids = torch.tensor([\n",
        "    [token_to_id['is'], token_to_id['the'], token_to_id[\"weather\"], token_to_id[\"today\"], token_to_id[\"<EOS>\"], token_to_id[\"sunny\"], token_to_id['<EOS>']],\n",
        "    [token_to_id['weather'], token_to_id['tomorrow'], token_to_id['is'], token_to_id['what'], token_to_id['<EOS>'], token_to_id['rainy'], token_to_id['<EOS>']],\n",
        "])\n",
        "\n",
        "train_data = TensorDataset(input_ids, output_ids)\n",
        "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "73oo5OcVQjD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model = 2, vocab_size = 6):\n",
        "\n",
        "        ## d_model is the dim word embeddings\n",
        "        ## max_len is length of longest sentence we can generate\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(vocab_size , d_model)\n",
        "\n",
        "        pos = torch.arange(0, vocab_size , step = 1, dtype = torch.float).unsqueeze(1) # (max_len, 1)\n",
        "        embedding_idx = torch.arange(0, d_model, step = 2, dtype = torch.float) # (d/2,)\n",
        "\n",
        "        div_term = 1 / torch.pow(10000, (2 * embedding_idx) / d_model)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term) # # (max_len, d/2)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0) # (1, max_len, d)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, word_embeddings):\n",
        "        B, L, d = word_embeddings.shape # expects shape (B, L, d)\n",
        "        return word_embeddings + (self.pe[:, :L, :]).requires_grad_(False)"
      ],
      "metadata": {
        "id": "ntQWaxwbK2py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias = False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias = False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias = False)\n",
        "\n",
        "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask = None):\n",
        "        # encodings_* shapes: (B, Lq, d), (B, Lk, d), (B, Lk, d)\n",
        "\n",
        "        Q = self.W_q(encodings_for_q) # (B, Lq, d)\n",
        "        K = self.W_k(encodings_for_k) # (B, Lk, d)\n",
        "        V = self.W_v(encodings_for_v) # (B, Lv, d)\n",
        "\n",
        "        ## softmax(Q * K^T / sqrt(d_k) + M) * V\n",
        "        similarity = Q @ K.transpose(-1, -2) # Q * K^T\n",
        "\n",
        "        # d_k\n",
        "        d_k = K.size(-1)\n",
        "\n",
        "        # scaled_simalrity = simalrity / torch.sqrt(torch.tensor(K.shape(-1))) # Q * K^T / sqrt(d_k)\n",
        "        scaled_similarity = similarity / math.sqrt(d_k)# Q * K^T / sqrt(d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_similarity = scaled_similarity.masked_fill(mask, float(\"-inf\")) # Q * K^T / sqrt(d_k) + M\n",
        "\n",
        "        attention_weights = F.softmax(scaled_similarity, dim = -1) # softmax(Q * K^T / sqrt(d_k) + M)\n",
        "\n",
        "        attention_scores = attention_weights @ V # softmax(Q * K^T / sqrt(d_k) + M) * V\n",
        "\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "eeFJliC_T49_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model = 2, num_tokens = 7, vocab_size  = 7):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings = num_tokens, embedding_dim = d_model)\n",
        "\n",
        "        self.pe = PositionEncoding(d_model = d_model, vocab_size  = vocab_size )\n",
        "\n",
        "        self.attention = Attention(d_model = d_model)\n",
        "\n",
        "        self.fc_layer = nn.Linear(d_model, num_tokens)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs: (B, L) of token ids\n",
        "        B, L = inputs.shape\n",
        "\n",
        "        word_embeddings = self.embedding(inputs)\n",
        "\n",
        "        pos_encoded = self.pe(word_embeddings)\n",
        "\n",
        "        device = inputs.device\n",
        "\n",
        "        mask = torch.triu(torch.ones(L, L, dtype=torch.bool, device=device), diagonal=1).unsqueeze(0)\n",
        "\n",
        "        self_attention_values = self.attention(pos_encoded, pos_encoded, pos_encoded, mask)\n",
        "\n",
        "        x = pos_encoded + self_attention_values # residual\n",
        "\n",
        "        outputs = self.fc_layer(x) # logits\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "ggt3vPIdfJdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MiniTransformer(num_tokens = len(token_to_id), d_model = 4, vocab_size  = 8)\n",
        "input = torch.tensor([token_to_id[\"what\"], token_to_id[\"is\"], token_to_id[\"the\"], token_to_id[\"weather\"], token_to_id[\"today\"], token_to_id[\"<EOS>\"]])\n",
        "\n",
        "input_length = input.size(0)\n",
        "predictions = model(input.unsqueeze(0)).squeeze(0)\n",
        "print(predictions)\n",
        "predicted_id = torch.tensor([torch.argmax(predictions[-1, :]).detach()])\n",
        "\n",
        "predicted_ids = predicted_id\n",
        "\n",
        "\n",
        "max_length = 8\n",
        "for i in range(input_length, max_length):\n",
        "    if (predicted_id == token_to_id[\"<EOS>\"]):\n",
        "        break\n",
        "    input = torch.cat((input, predicted_id))\n",
        "    predictions = model(input.unsqueeze(0)).squeeze(0)\n",
        "    predicted_id = torch.tensor([torch.argmax(predictions[-1, :]).detach()])\n",
        "    predicted_ids = torch.cat((predicted_ids, predicted_id))\n",
        "\n",
        "for id in predicted_ids:\n",
        "    print(id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpnH9hLyvD4H",
        "outputId": "51511f6c-7b0d-4815-8b60-971abfb092e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2740,  0.5111,  0.0956, -0.0421, -0.0670,  0.0806, -0.5995,  0.1890,\n",
            "          0.3308],\n",
            "        [ 0.0697,  0.3292,  0.2620,  0.3418, -0.1364, -0.1057, -1.0411,  0.5543,\n",
            "          0.7982],\n",
            "        [-0.5329,  0.4758,  0.8326,  0.0513, -0.7108,  0.5784, -1.5123, -0.2275,\n",
            "          1.3688],\n",
            "        [-0.3688,  0.2516,  0.1850, -0.0841, -0.1508,  0.0390, -0.6402,  0.3330,\n",
            "          0.1737],\n",
            "        [-0.1234, -0.2856, -0.7494,  0.3713,  1.0057,  1.6562, -0.3639,  0.2104,\n",
            "          0.9847],\n",
            "        [-0.0229, -0.0760, -0.8187,  0.3896,  1.0547,  1.5280, -0.2904,  0.1791,\n",
            "          0.9768]], grad_fn=<SqueezeBackward1>)\n",
            "sunny\n",
            "is\n",
            "tomorrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## training process\n",
        "model = MiniTransformer(num_tokens = len(token_to_id), d_model = 16, vocab_size  = 8)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-2, weight_decay = 1e-3)\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    for X, y in train_loader:\n",
        "\n",
        "        y_pred = model(X)\n",
        "        B, L, d = y_pred.shape\n",
        "        loss = loss_fn(y_pred.view(B*L, d), y.view(B*L))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# X, y = next(iter(train_loader))\n",
        "# print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "Flx4cnZ049QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id in input_ids[0]:\n",
        "    print(id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwKo5KSsDGzg",
        "outputId": "0289a68b-1392-4da4-be1b-d8a00144059e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what\n",
            "is\n",
            "the\n",
            "weather\n",
            "today\n",
            "<EOS>\n",
            "sunny\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "# input = torch.tensor([token_to_id[\"what\"], token_to_id[\"is\"], token_to_id[\"the\"], token_to_id[\"weather\"], token_to_id[\"today\"], token_to_id[\"<EOS>\"]])\n",
        "# input = torch.tensor([token_to_id[\"the\"], token_to_id[\"weather\"], token_to_id[\"is\"], token_to_id[\"what\"], token_to_id[\"tomorrow\"], token_to_id[\"<EOS>\"]])\n",
        "# input = torch.tensor([token_to_id[\"what\"], token_to_id[\"is\"], token_to_id[\"the\"], token_to_id[\"weather\"], token_to_id[\"tomorrow\"], token_to_id[\"<EOS>\"]])\n",
        "predictions = model(input.unsqueeze(0)).squeeze(0)\n",
        "predicted_id = torch.tensor([torch.argmax(predictions[-1, :]).detach()])\n",
        "predicted_ids = predicted_id\n",
        "\n",
        "max_length = 8\n",
        "for i in range(input_length, max_length):\n",
        "    if (predicted_id == token_to_id[\"<EOS>\"]):\n",
        "        break\n",
        "    input = torch.cat((input, predicted_id))\n",
        "    predictions = model(input.unsqueeze(0)).squeeze(0)\n",
        "    predicted_id = torch.tensor([torch.argmax(predictions[-1, :]).detach()])\n",
        "    predicted_ids = torch.cat((predicted_ids, predicted_id))\n",
        "\n",
        "for id in predicted_ids:\n",
        "    print(id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtY5renAAmc8",
        "outputId": "e0634527-39dd-48f8-af28-52a5de6c2ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rainy\n",
            "<EOS>\n"
          ]
        }
      ]
    }
  ]
}